{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 XPath 解析网页\n",
    "\n",
    "XPath 是一种在 XML/HTML 文档中定位节点的语言, 在爬虫中常用于精准提取数据。本文示例主要基于 lxml 与 parsel 两个库。"
   ],
   "id": "127e0667f21a4d5e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装依赖\n",
    "```shell\n",
    "pip install lxml parsel chardet\n",
    "```\n",
    "- lxml: 高性能 HTML/XML 解析器\n",
    "- parsel: 对 XPath/CSS 进一步封装, 与 scrapy 中 Selector 一致\n",
    "- chardet: 可选, 用于编码检测"
   ],
   "id": "d0552f3f085a7355"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一段示例 HTML\n",
    "我们以一段简化的 HTML 作为练习:"
   ],
   "id": "2656e594e758893d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:18:15.826943Z",
     "start_time": "2025-11-13T11:18:15.822091Z"
    }
   },
   "source": [
    "html = '''\\n",
    "<html>\\n",
    "  <head>\\n",
    "    <title>示例页面 - 测试</title>\\n",
    "  </head>\\n",
    "  <body>\\n",
    "    <div id=\"container\" class=\"main wrap\">\\n",
    "      <h1 class=\"title\">主标题<span>副标题</span></h1>\\n",
    "      <ul class=\"items\">\\n",
    "        <li data-id=\"1001\"><a href=\"/detail/1001\">苹果</a></li>\\n",
    "        <li data-id=\"1002\"><a href=\"/detail/1002\">香蕉</a></li>\\n",
    "        <li data-id=\"1003\"><a href=\"/detail/1003\">菠萝</a></li>\\n",
    "      </ul>\\n",
    "      <p class=\"desc\">  这是 一个 带有   多余空格 的 描述。 </p>\\n",
    "      <div class=\"links\">\\n",
    "        <a href=\"https://example.com/about\" class=\"nav\">关于我们</a>\\n",
    "        <a href=\"https://example.com/contact\" class=\"nav external\">联系我们</a>\\n",
    "      </div>\\n",
    "    </div>\\n",
    "  </body>\\n",
    "</html>\\n",
    "'''"
   ],
   "id": "f1d47e85b99b1115",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 lxml.etree 加载与 XPath 查询\n",
    "lxml 的 html.fromstring 能自动容错解析非严格 HTML。"
   ],
   "id": "3591dc3bd2035595"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:18:15.886421Z",
     "start_time": "2025-11-13T11:18:15.874893Z"
    }
   },
   "source": [
    "from lxml import html as lxml_html\n",
    "tree = lxml_html.fromstring(html)  # 构建 DOM 树\n",
    "\n",
    "# 1. 选取 <title> 文本\n",
    "title_text = tree.xpath('//title/text()')[0]\n",
    "print('页面标题:', title_text)\n",
    "\n",
    "# 2. 选取所有商品名称 (li 下 a 文本)\n",
    "items = tree.xpath('//ul[@class=\"items\"]/li/a/text()')\n",
    "print('商品列表:', items)\n",
    "\n",
    "# 3. 获取第二个 li 的 data-id (位置选择)\n",
    "second_id = tree.xpath('//ul[@class=\"items\"]/li[2]/@data-id')[0]\n",
    "print('第二个商品ID:', second_id)\n",
    "\n",
    "# 4. 获取 class 包含 external 的链接 href\n",
    "external_href = tree.xpath('//a[contains(@class, \"external\")]/@href')[0]\n",
    "print('external链接:', external_href)\n",
    "\n",
    "# 5. 使用 normalize-space 去除多余空格\n",
    "desc = tree.xpath('normalize-space(//p[@class=\"desc\"])')\n",
    "print('描述(去空格):', desc)\n",
    "\n",
    "# 6. 选取副标题 span 文本\n",
    "subtitle = tree.xpath('//h1[@class=\"title\"]/span/text()')[0]\n",
    "print('副标题:', subtitle)"
   ],
   "id": "34086a57818fb7e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "页面标题: 示例页面 - 测试\n",
      "商品列表: ['苹果', '香蕉', '菠萝']\n",
      "第二个商品ID: 1002\n",
      "external链接: https://example.com/contact\n",
      "描述(去空格): 这是 一个 带有 多余空格 的 描述。\n",
      "副标题: 副标题\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见 XPath 语法速查\n",
    "| 场景 | XPath 示例 | 说明 |\n",
    "|------|------------|------|\n",
    "| 根节点匹配 | `/html/body` | 从根逐层 |\n",
    "| 任意层级 | `//div` | 匹配所有 div |\n",
    "| 属性过滤 | `//ul[@class='items']` | 精确属性 |\n",
    "| 包含属性 | `//a[contains(@class,'nav')]` | 模糊 class |\n",
    "| 多条件 AND | `//a[@class='nav'][contains(@href,'contact')]` | 链式条件 |\n",
    "| 取文本 | `//h1/text()` | 当前节点直接文本 |\n",
    "| 所有后代文本 | `//h1//text()` | 包含子孙 |\n",
    "| 属性值 | `//li/@data-id` | 取属性 |\n",
    "| 位置 | `//li[1]` | 第一    (从1开始) |\n",
    "| 最后一个 | `//li[last()]` | 尾元素 |\n",
    "| 条件函数 | `//a[starts-with(@href,'https://')]` | 前缀判断 |\n",
    "| 计数 | `count(//li)` | 统计节点数 |\n",
    "| 去空格 | `normalize-space(//p)` | 清理空白 |\n",
    "| 上级/父节点 | `//span/..` | 返回父节点 |\n",
    "| 轴: following-sibling | `//li[@data-id='1001']/following-sibling::li` | 后面同级 |\n",
    "| 轴: preceding-sibling | `//li[@data-id='1003']/preceding-sibling::li` | 前面同级 |"
   ],
   "id": "934f0a6b0699d2b1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取真实网页示例\n",
    "以 httpbin.org 为例(演示结构解析), 实际生产中需处理编码与容错。"
   ],
   "id": "36d8e50ca3323297"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:18:30.242247Z",
     "start_time": "2025-11-13T11:18:15.990799Z"
    }
   },
   "source": [
    "import requests, chardet\n",
    "url = 'https://httpbin.org/html'  # 返回一段简单 HTML\n",
    "resp = requests.get(url, timeout=10)\n",
    "# 编码检测 (有些站点未正确声明)\n",
    "raw = resp.content\n",
    "enc = chardet.detect(raw)['encoding'] or resp.apparent_encoding or 'utf-8'\n",
    "text = raw.decode(enc, errors='ignore')\n",
    "doc = lxml_html.fromstring(text)\n",
    "\n",
    "# 提取所有链接与段落\n",
    "links = doc.xpath('//a/@href')\n",
    "paras = [p.strip() for p in doc.xpath('//p//text()') if p.strip()]\n",
    "print('链接:', links)\n",
    "print('段落:', paras[:3], '...')\n",
    "# 安全获取节点文本的封装函数\n",
    "def xtext(node, path, default=None):\n",
    "    try:\n",
    "        r = node.xpath(path)\n",
    "        return r[0] if r else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "print('示例 title:', xtext(doc, '//title/text()', 'N/A'))"
   ],
   "id": "b78b2a558d256acc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "链接: []\n",
      "段落: [\"Availing himself of the mild, summer-cool weather that now reigned in these latitudes, and in preparation for the peculiarly active pursuits shortly to be anticipated, Perth, the begrimed, blistered old blacksmith, had not removed his portable forge to the hold again, after concluding his contributory work for Ahab's leg, but still retained it on deck, fast lashed to ringbolts by the foremast; being now almost incessantly invoked by the headsmen, and harpooneers, and bowsmen to do some little job for them; altering, or repairing, or new shaping their various weapons and boat furniture. Often he would be surrounded by an eager circle, all waiting to be served; holding boat-spades, pike-heads, harpoons, and lances, and jealously watching his every sooty movement, as he toiled. Nevertheless, this old man's was a patient hammer wielded by a patient arm. No murmur, no impatience, no petulance did come from him. Silent, slow, and solemn; bowing over still further his chronically broken back, he toiled away, as if toil were life itself, and the heavy beating of his hammer the heavy beating of his heart. And so it was.â€”Most miserable! A peculiar walk in this old man, a certain slight but painful appearing yawing in his gait, had at an early period of the voyage excited the curiosity of the mariners. And to the importunity of their persisted questionings he had finally given in; and so it came to pass that every one now knew the shameful story of his wretched fate. Belated, and not innocently, one bitter winter's midnight, on the road running between two country towns, the blacksmith half-stupidly felt the deadly numbness stealing over him, and sought refuge in a leaning, dilapidated barn. The issue was, the loss of the extremities of both feet. Out of this revelation, part by part, at last came out the four acts of the gladness, and the one long, and as yet uncatastrophied fifth act of the grief of his life's drama. He was an old man, who, at the age of nearly sixty, had postponedly encountered that thing in sorrow's technicals called ruin. He had been an artisan of famed excellence, and with plenty to do; owned a house and garden; embraced a youthful, daughter-like, loving wife, and three blithe, ruddy children; every Sunday went to a cheerful-looking church, planted in a grove. But one night, under cover of darkness, and further concealed in a most cunning disguisement, a desperate burglar slid into his happy home, and robbed them all of everything. And darker yet to tell, the blacksmith himself did ignorantly conduct this burglar into his family's heart. It was the Bottle Conjuror! Upon the opening of that fatal cork, forth flew the fiend, and shrivelled up his home. Now, for prudent, most wise, and economic reasons, the blacksmith's shop was in the basement of his dwelling, but with a separate entrance to it; so that always had the young and loving healthy wife listened with no unhappy nervousness, but with vigorous pleasure, to the stout ringing of her young-armed old husband's hammer; whose reverberations, muffled by passing through the floors and walls, came up to her, not unsweetly, in her nursery; and so, to stout Labor's iron lullaby, the blacksmith's infants were rocked to slumber. Oh, woe on woe! Oh, Death, why canst thou not sometimes be timely? Hadst thou taken this old blacksmith to thyself ere his full ruin came upon him, then had the young widow had a delicious grief, and her orphans a truly venerable, legendary sire to dream of in their after years; and all of them a care-killing competency.\"] ...\n",
      "示例 title: N/A\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 parsel.Selector\n",
    "parsel 提供更链式的 API, 支持 XPath 与 CSS 混用。"
   ],
   "id": "8491f8cac3ec0e8f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:18:30.301063Z",
     "start_time": "2025-11-13T11:18:30.268553Z"
    }
   },
   "source": [
    "from parsel import Selector\n",
    "sel = Selector(text=html)\n",
    "# XPath\n",
    "titles = sel.xpath('//ul[@class=\"items\"]/li/a/text()').getall()\n",
    "print('parsel 商品:', titles)\n",
    "# get() 只取第一个, getall() 取全部\n",
    "first_href = sel.xpath('//ul[@class=\"items\"]/li[1]/a/@href').get()\n",
    "print('第一个href:', first_href)\n",
    "# CSS 选择器混用\n",
    "nav_texts = sel.css('div.links a.nav::text').getall()\n",
    "print('导航文本:', nav_texts)\n",
    "# 链式过滤: 先选节点再取属性\n",
    "hrefs_chain = sel.css('ul.items li a').xpath('./@href').getall()\n",
    "print('链式href:', hrefs_chain)"
   ],
   "id": "505ea37d68879cd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsel 商品: ['苹果', '香蕉', '菠萝']\n",
      "第一个href: /detail/1001\n",
      "导航文本: ['关于我们', '联系我们']\n",
      "链式href: ['/detail/1001', '/detail/1002', '/detail/1003']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 复杂条件与常见模式\n",
    "1. 根据多个属性: `//a[@class='nav' and contains(@href,'contact')]`\n",
    "2. 排除某些节点: `//a[not(contains(@class,'external'))]`\n",
    "3. 选择第 2~最后一个节点: `//li[position()>1]`\n",
    "4. 选择文本包含某关键词: `//li[a[contains(text(),'果')]]`\n",
    "5. 嵌套取属性后再跳回父节点: `//a[contains(@href,'detail')]/../@data-id`\n",
    "6. 相对路径区别: `./` 表示从当前节点开始, `//` 表示任意后代。"
   ],
   "id": "4e332a0feb330d94"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见坑与技巧\n",
    "- HTML 不规范: 优先使用 `lxml.html.fromstring`, 少用纯 xml 解析。\n",
    "- 多余空白: 使用 `normalize-space()` 或 Python `strip()`。\n",
    "- class 多值匹配: 不要用等号硬匹配时可用 `contains(@class,'name')`。\n",
    "- 性能: 合并 XPath 查询, 避免在循环中反复 `xpath()` 大量小查询。\n",
    "- 容错: 写辅助函数安全取值(见上 xtext)。\n",
    "- 调试: 输出 `etree.tostring(node, pretty_print=True).decode()` 查看结构。\n",
    "- 编码: 使用 `resp.content` + chardet 检测, 避免乱码影响匹配。\n",
    "- 动态页面: 需结合 Selenium 或请求其 AJAX 接口, XPath 只解析已有 HTML。"
   ],
   "id": "2b28d93bc52577d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "1. XPath 用于精准定位, 与正则相比更稳定。\n",
    "2. 熟练掌握节点定位、条件过滤、文本与属性提取是关键。\n",
    "3. parsel 提升易用性, 在 scrapy 中几乎同样用法。\n",
    "4. 遇到复杂结构先 prettify/打印节点, 再逐步收窄 XPath。"
   ],
   "id": "dd25d6704009a8ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 详细分解复杂 XPath 表达式\n",
    "\n",
    "\n",
    "### 获取 class 包含 j_readContent 的 div 内所有文本节点\n",
    "`//div[contains(concat(' ', normalize-space(@class), ' '), ' j_readContent ')]//text()`\n",
    "\n",
    "组成部分说明:\n",
    "\\- `//div`：从文档根部选取所有 `div` 元素 (任意层级后代)。\n",
    "\\- `[ ... ]`：谓词过滤，只保留满足条件的 `div`。\n",
    "\\- `@class`：获取该元素的 `class` 属性字符串。\n",
    "\\- `normalize-space(@class)`：去掉首尾空白并把中间连续空白压缩为单个空格，标准化类名列表。\n",
    "\\- `concat(' ', normalize-space(@class), ' ')`：在标准化后的类串前后各拼接一个空格，形成模式 `\" class1 class2 class3 \"`，为后续“整词匹配”制造边界。\n",
    "\\- `contains( ..., ' j_readContent ')`：检查是否包含带前后空格的子串 `' j_readContent '`，只在独立类名存在时匹配，避免误匹配 `j_readContentExtra`、`my_j_readContent_old` 等。\n",
    "\\- `//text()`：在匹配的 `div` 内继续向下选取所有后代文本节点（包括嵌套标签中的文本）。\n",
    "\n",
    "为何不直接用 `//div[contains(@class,'j_readContent')]//text()`:\n",
    "\\- 该写法会匹配任何包含该子串的类值，易误伤类似 `j_readContentExtra`。\n",
    "\\- 使用空格包裹后通过“整词”判定，确保只匹配独立的类名 `j_readContent`。\n",
    "\n",
    "要只取该 `div` 直接子级文本可改为:\n",
    "`//div[contains(concat(' ', normalize-space(@class), ' '), ' j_readContent ')]/text()`\n",
    "\n",
    "示例提取并清洗:\n",
    "```python\n",
    "from parsel import Selector\n",
    "\n",
    "def extract_content(html: str):\n",
    "    sel = Selector(html)\n",
    "    texts = sel.xpath(\"//div[contains(concat(' ', normalize-space(@class), ' '), ' j_readContent ')]//text()\").getall()\n",
    "    return \"\\n\".join(t.strip() for t in texts if t.strip())\n",
    "```\n",
    "\n",
    "要匹配多个类名同时存在(例如同时包含 `j_readContent` 与 `active`):\n",
    "```python\n",
    "xpath = (\"//div\"\n",
    "         \"[contains(concat(' ', normalize-space(@class), ' '), ' j_readContent ')\"\n",
    "         \" and contains(concat(' ', normalize-space(@class), ' '), ' active ')]\")\n",
    "```"
   ],
   "id": "549e6ba3573eaa58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
