{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 并发编程笔记\n",
    "\n",
    "本笔记系统整理 Python 并发相关核心概念与实践：**进程 (multiprocessing)、线程 (threading)、协程 (asyncio)**，以及 **同步 vs 异步、阻塞 vs 非阻塞**、GIL、适用场景、常见原语、性能与陷阱、调试与优化策略。全部示例使用标准库，便于直接运行。\n",
    "\n",
    "> 快速结论：\n",
    "> - CPU 密集：优先多进程 (绕过 GIL) 或 C 扩展\n",
    "> - IO 密集：线程池 或 asyncio (大量并发连接/等待)\n",
    "> - 简单并行 map：concurrent.futures (统一接口)\n",
    "> - 大量高并发、少阻塞：asyncio；需要生态 (HTTP/DB) 时选支持异步的库\n",
    "> - 混合场景：主结构 asyncio，CPU 子任务 run_in_executor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 并发 vs 并行 vs 异步 概念速览\n",
    "- 并发 (Concurrency)：逻辑上交错执行 (调度切换)\n",
    "- 并行 (Parallelism)：物理上同时执行 (多核)\n",
    "- 同步：调用发起后等待完成再继续\n",
    "- 异步：调用发起立即返回，通过回调/未来对象/事件循环获取结果\n",
    "- 阻塞：当前执行流无法继续 (等待 IO/锁)\n",
    "- 非阻塞：立即返回 (可能只返回状态/需轮询)\n",
    "\n",
    "Python 解释器层面：GIL (Global Interpreter Lock) 在 **CPython** 中保证同一时刻只有一个线程执行字节码，影响多线程 CPU 绑定任务，但 IO 密集不显著。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GIL 是什么 & 影响\n",
    "- 目的：简化内存管理 (对象引用计数)\n",
    "- 后果：多线程无法在单进程内真正利用多核进行 Python 计算 (CPU 密集)\n",
    "- IO 密集：线程等待 IO 释放 GIL，其他线程可继续\n",
    "- 规避：多进程、C 扩展、NumPy (内部释放 GIL)、PyPy (部分差异)、或用异步 IO\n",
    "- 误区：\n",
    "  - \"多线程一定更快\" (CPU 密集反而慢)\n",
    "  - \"协程能提高 CPU 计算速度\" (协程主要减少 IO 等待切换开销)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. threading 基础示例\n",
    "适合：IO 密集，少量并发 (<1000)，代码简单。\n",
    "风险：共享状态竞争、死锁。使用 Lock/RLock。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T08:43:30.101530Z",
     "start_time": "2025-11-14T08:43:30.058887Z"
    }
   },
   "source": [
    "import threading, time\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def unsafe_inc(n):\n",
    "    global counter\n",
    "    for _ in range(n):\n",
    "        # 演示竞争：不加锁可能丢失更新\n",
    "        tmp = counter\n",
    "        tmp += 1\n",
    "        counter = tmp\n",
    "\n",
    "def safe_inc(n):\n",
    "    global counter\n",
    "    for _ in range(n):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "def run(func, thread_count=10, each=10000):\n",
    "    global counter\n",
    "    counter = 0\n",
    "    threads = [ threading.Thread(target=func, args=(each,)) for _ in range(thread_count) ]\n",
    "    start = time.perf_counter()\n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(func.__name__, 'counter=', counter, 'elapsed=', round(elapsed, 4))\n",
    "\n",
    "run(unsafe_inc)  # 理论应=100000\n",
    "run(safe_inc)    # 正确值=100000"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsafe_inc counter= 100000 elapsed= 0.0093\n",
      "safe_inc counter= 100000 elapsed= 0.0209\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 常用同步原语\n",
    "- Lock / RLock：互斥 (RLock 可重入)\n",
    "- Semaphore：限制并发数量 (资源池)\n",
    "- Event：线程间信号触发\n",
    "- Condition：等待特定条件，配合锁\n",
    "- Queue：线程安全队列 (推荐传递工作)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T08:43:30.620902Z",
     "start_time": "2025-11-14T08:43:30.109265Z"
    }
   },
   "source": [
    "import threading, queue, time\n",
    "q = queue.Queue()\n",
    "STOP = object()\n",
    "\n",
    "def producer():\n",
    "    for i in range(5):\n",
    "        q.put(i)\n",
    "    q.put(STOP)\n",
    "\n",
    "def consumer():\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item is STOP:\n",
    "            break\n",
    "        print('consume', item)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "th1 = threading.Thread(target=producer)\n",
    "th2 = threading.Thread(target=consumer)\n",
    "th1.start(); th2.start(); th1.join(); th2.join()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consume 0\n",
      "consume 1\n",
      "consume 2\n",
      "consume 3\n",
      "consume 4\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. multiprocessing 基础示例\n",
    "适合：CPU 密集或需要真正多核。\n",
    "注意：Windows 必须放在 `if __name__ == '__main__':` 下，否则无法安全 spawn 进程。\n",
    "通信：Queue / Pipe / Manager / shared memory。开销：进程启动与序列化 (pickle)。\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-14T08:43:30.632868Z"
    }
   },
   "source": [
    "from multiprocessing import Process, Queue, cpu_count\n",
    "import math, time\n",
    "\n",
    "def heavy(n):\n",
    "    # 计算密集：近似求 pi 的一部分\n",
    "    s = 0.0\n",
    "    for k in range(n):\n",
    "        s += 4.0 * (-1)**k / (2*k + 1)\n",
    "    return s\n",
    "\n",
    "def worker(n, q):\n",
    "    q.put(heavy(n))\n",
    "\n",
    "def run_mp():\n",
    "    q = Queue()\n",
    "    tasks = [2000000] * cpu_count()\n",
    "    ps = [Process(target=worker, args=(t, q)) for t in tasks]\n",
    "    start = time.perf_counter()\n",
    "    [p.start() for p in ps]\n",
    "    results = [q.get() for _ in ps]\n",
    "    [p.join() for p in ps]\n",
    "    print('multi-process took', round(time.perf_counter() - start, 2), 'results sample', results[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_mp()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 concurrent.futures 统一接口\n",
    "提供 ThreadPoolExecutor / ProcessPoolExecutor：submit / map / as_completed 简化使用。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def io_task(x):\n",
    "    time.sleep(0.2)\n",
    "    return x * 2\n",
    "\n",
    "def cpu_task(x):\n",
    "    s = 0\n",
    "    for i in range(200000):\n",
    "        s += i * x\n",
    "    return s\n",
    "\n",
    "def demo_futures():\n",
    "    with ThreadPoolExecutor(max_workers=5) as tp:\n",
    "        futures = [tp.submit(io_task, i) for i in range(10)]\n",
    "        for f in as_completed(futures):\n",
    "            print('thread result', f.result())\n",
    "    with ProcessPoolExecutor() as pp:\n",
    "        for res in pp.map(cpu_task, range(5)):\n",
    "            print('process result sample', res)\n",
    "\n",
    "demo_futures()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. asyncio 协程与事件循环\n",
    "场景：海量并发 IO (网络、磁盘、sleep)；减少线程上下文切换和内存。核心：事件循环 + Task + Future。\n",
    "协程：`async def` 定义；切换点：`await`。\n",
    "调度：单线程内可挂起与恢复。\n",
    "网络库：aiohttp、httpx(异步)、asyncpg、aioredis 等。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asyncio, time\n",
    "\n",
    "async def fake_io(idx):\n",
    "    await asyncio.sleep(0.2)\n",
    "    return idx * 10\n",
    "\n",
    "async def main():\n",
    "    start = time.perf_counter()\n",
    "    tasks = [asyncio.create_task(fake_io(i)) for i in range(10)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print('async results', results)\n",
    "    print('elapsed', round(time.perf_counter() - start, 3))\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 使用 Semaphore 控制并发数量\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asyncio, random\n",
    "sem = asyncio.Semaphore(3)  # 限流\n",
    "\n",
    "async def limited_task(i):\n",
    "    async with sem:\n",
    "        await asyncio.sleep(random.uniform(0.1,0.3))\n",
    "        print('done', i)\n",
    "\n",
    "async def run_all():\n",
    "    await asyncio.gather(*[limited_task(i) for i in range(10)])\n",
    "\n",
    "asyncio.run(run_all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 在 asyncio 中调用阻塞 CPU 任务\n",
    "使用 `loop.run_in_executor` 或 `asyncio.to_thread` (3.9+) 避免阻塞事件循环。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asyncio, math\n",
    "def cpu_blocking(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += math.sqrt(i)\n",
    "    return s\n",
    "\n",
    "async def wrapper():\n",
    "    # 将阻塞函数移动到线程池 (默认)\n",
    "    result = await asyncio.to_thread(cpu_blocking, 100000)\n",
    "    print('cpu result', round(result, 2))\n",
    "\n",
    "asyncio.run(wrapper())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 同步原语对比 (线程 vs 协程)\n",
    "| 原语 | threading | asyncio | 说明 |\n",
    "|------|----------|---------|------|\n",
    "| Lock | Lock/RLock | `asyncio.Lock` | 协程锁需 `async with` |\n",
    "| Semaphore | Semaphore | `asyncio.Semaphore` | 控制并发 |\n",
    "| Event | Event | `asyncio.Event` | 协程间信号 |\n",
    "| Queue | queue.Queue | `asyncio.Queue` | 非阻塞 await |\n",
    "| Condition | Condition | `asyncio.Condition` | 复杂等待 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CPU vs IO 场景对比简易基准 (示意)\n",
    "避免实际执行时间过长，下面缩小规模示例："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time, threading, asyncio\n",
    "\n",
    "def fake_io_block(n):\n",
    "    time.sleep(0.1)\n",
    "    return n\n",
    "\n",
    "def thread_test():\n",
    "    start = time.perf_counter()\n",
    "    res = []\n",
    "    def run(n): res.append(fake_io_block(n))\n",
    "    ts = [threading.Thread(target=run, args=(i,)) for i in range(20)]\n",
    "    [t.start() for t in ts]; [t.join() for t in ts]\n",
    "    print('threads elapsed', round(time.perf_counter() - start, 3))\n",
    "\n",
    "async def async_test():\n",
    "    start = time.perf_counter()\n",
    "    async def aio(n):\n",
    "        await asyncio.sleep(0.1)\n",
    "        return n\n",
    "    await asyncio.gather(*[aio(i) for i in range(20)])\n",
    "    print('async elapsed', round(time.perf_counter() - start, 3))\n",
    "\n",
    "thread_test()\n",
    "asyncio.run(async_test())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 常见陷阱\n",
    "- 死锁：锁嵌套顺序不一致 -> 避免循环等待\n",
    "- 竞争条件：共享变量未保护 -> 使用锁或队列\n",
    "- 资源泄漏：线程/进程不 join -> 主进程退出混乱\n",
    "- 过度线程：几千阻塞线程 -> 内存与调度开销高\n",
    "- 协程中调用阻塞 IO (如 requests)：阻塞事件循环 -> 换异步库或 run_in_executor\n",
    "- multiprocessing 在 Windows 未加   护 -> 无限递归创建进程\n",
    "- 大对象频繁跨进程传递 -> 序列化瓶颈\n",
    "- asyncio 忘记 `await` -> 协程对象未执行\n",
    "- 使用 time.sleep() 代替 asyncio.sleep() -> 阻塞 loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 调试与诊断\n",
    "- threading.enumerate() 查看活跃线程\n",
    "- faulthandler / logging 跟踪死锁位置\n",
    "- asyncio.run() 外层只调用一次，内部使用 `create_task` 管理\n",
    "- 使用 `asyncio.Task.get_coro()` 查看任务来源 (3.10+)\n",
    "- profile：cProfile + snakeviz；IO 分析用系统工具 (netstat, lsof)\n",
    "- 超时：`asyncio.wait_for` / futures.result(timeout=) 防止永久挂起\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 第三方生态简述 (不深入示例)\n",
    "| 类别 | 库 | 特点 |\n",
    "|------|----|------|\n",
    "| 异步 HTTP | aiohttp / httpx | 客户端/服务端支持 |\n",
    "| 异步 DB | asyncpg / aiomysql / sqlalchemy(async) | 高并发数据库访问 |\n",
    "| 协程框架 | trio / curio | 不同调度模型，结构化并发 |\n",
    "| 协程补丁 | gevent / eventlet | 通过 monkey patch 让阻塞 IO 变协作式 |\n",
    "| 分布式任务 | Celery / RQ / Dramatiq | 进程池 + 队列异步执行 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 选择策略速查\n",
    "| 场景 | 推荐 | 原因 |\n",
    "|------|------|------|\n",
    "| CPU 密集 (计算/压缩) | multiprocessing / C 扩展 | 多核 / 释放 GIL |\n",
    "| IO 密集 少量并发 | ThreadPoolExecutor | 简单、API 友好 |\n",
    "| IO 密集 海量并发 | asyncio | 单线程调度 + 低开销 |\n",
    "| 简单批量 map | concurrent.futures.map | 最少样板代码 |\n",
    "| 混合 (网络 + CPU) | asyncio + run_in_executor | 分离 IO/CPU |\n",
    "| 多进程通信 | multiprocessing.Queue/Manager | 共享/传递数据 |\n",
    "| 需要取消任务 | asyncio (Task.cancel) | 协程取消语义完备 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 总结\n",
    "- 明确瓶颈类型：先 profile 再选工具\n",
    "- 线程适度使用，避免过量阻塞堆积\n",
    "- 协程不是魔法：只加速大量等待；要使用异步库栈\n",
    "- CPU 重任务不要强行线程/协程，选进程或本地优化 (NumPy/向量化)\n",
    "- 正确使用同步原语，优先消息传递 (Queue) 替代共享变量\n",
    "- 设计可取消、可超时的并发任务，避免僵尸运行\n",
    "- 渐进迁移：先抽象接口，再替换执行模型 (同步->异步)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
