{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 使用 CSS 选择器解析网页\n",
    "\n",
    "本笔记系统整理了在 Python 中使用 **CSS 选择器 (CSS Selectors)** 提取网页内容的常见方式，涵盖 `parsel` (基于 lxml)、`BeautifulSoup`、`pyquery`、`lxml` 原生、以及高性能的 `selectolax`。同时给出常见选择器模式、技巧、容易踩的坑与性能建议。\n",
    "```shell\n",
    "pip install parsel beautifulsoup4 lxml pyquery selectolax\n",
    "```"
   ],
   "id": "9ddacb5406ef16bd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CSS 选择器速览\n",
    "常见模式 (与浏览器开发者工具一致)：\n",
    "- `tag` 标签名，如 `div`, `a`, `li`\n",
    "- `.class` 类名 (单个)；多个类：`.item.active` (与)\n",
    "- `#id` 唯一 id\n",
    "- `tag.class` 组合：`div.container`\n",
    "- 子代 `parent > child`：`ul > li` 仅直接子元素\n",
    "- 后代 `ancestor descendant`：`div a` 任意深度后代\n",
    "- 相邻兄弟 `prev + next`；一般兄弟 `prev ~ siblings`\n",
    "- 属性选择：`a[href]`，`a[href^=https]`，`img[src$=.png]`，`a[data-id*=123]`\n",
    "- 伪类 (lxml 不支持全部)：`:first-child`, `:nth-child(2)`, `:last-child` 等 (不同库支持度不同)\n",
    "- 取文本/属性：多数库提供额外 API，不用在选择器里写。\n",
    "\n",
    "> 与 XPath 对比：CSS 更简洁但在处理复杂层级或条件过滤时 XPath 更强。"
   ],
   "id": "3fbc36c648126622"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备：统一示例 HTML\n",
    "下面构造一段示例 HTML，重复使用，避免网络不稳定影响演示。"
   ],
   "id": "92a3ee992ed7c13f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:18.222495Z",
     "start_time": "2025-11-13T11:30:18.218687Z"
    }
   },
   "source": [
    "sample_html = '''\\n",
    "<html>\\n",
    "  <head><title>Demo Page</title></head>\\n",
    "  <body>\\n",
    "    <div id=\"main\" class=\"container\">\\n",
    "      <h1 class=\"title\">示例标题</h1>\\n",
    "      <ul class=\"items\">\\n",
    "        <li class=\"item active\" data-id=\"101\">苹果 <a href=\"/detail/101\" class=\"detail\">详情</a></li>\\n",
    "        <li class=\"item\" data-id=\"102\">香蕉 <a href=\"/detail/102\" class=\"detail\">详情</a></li>\\n",
    "        <li class=\"item\" data-id=\"103\">梨子 <a href=\"/detail/103\" class=\"detail\">详情</a></li>\\n",
    "      </ul>\\n",
    "      <p class=\"desc\">水果列表示例，用于 CSS Selector 练习。</p>\\n",
    "      <div class=\"nested\">\\n",
    "        <span class=\"note\">附注 A</span>\\n",
    "        <span class=\"note\">附注 B</span>\\n",
    "      </div>\\n",
    "    </div>\\n",
    "    <footer>Copyright <span>2025</span></footer>\\n",
    "  </body>\\n",
    "</html>\\n",
    "'''\n",
    "print(sample_html.splitlines()[0], '... 共', len(sample_html.splitlines()), '行')"
   ],
   "id": "6a6ea8dbdb7ed1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... 共 20 行\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. parsel (Scrapy 常用)\n",
    "`parsel.Selector` 提供 `.css()` 和 `.xpath()` 双接口。CSS 中获取文本和属性使用伪选择器：`::text` 与 `::attr(name)`。适合快速统一写法。"
   ],
   "id": "454d23f1a13e7831"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:18.255260Z",
     "start_time": "2025-11-13T11:30:18.245566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from parsel import Selector\n",
    "sel = Selector(text=sample_html)\n",
    "# 选取所有 li.item 的纯文本 (包含子节点文本汇总)\n",
    "items_text = sel.css('li.item::text').getall()  # 只取 li 直接文本 (不含 <a> 内文)\n",
    "items_full = [li.get().strip() for li in sel.css('li.item')]\n",
    "print('items_text:', items_text)\n",
    "print('items_full 示例:', items_full[0][:40], '...')\n",
    "# 选取激活项 data-id\n",
    "active_id = sel.css('li.item.active::attr(data-id)').get()\n",
    "print('active id:', active_id)\n",
    "# 获取所有详情链接 href\n",
    "detail_hrefs = sel.css('a.detail::attr(href)').getall()\n",
    "print(detail_hrefs)\n",
    "# 组合选择器：ul.items > li:first-child\n",
    "first_li_text = sel.css('ul.items > li:first-child::text').get()\n",
    "print('first li text:', first_li_text)\n",
    "# 后代 + 属性前缀匹配\n",
    "links_prefix = sel.css('div.container a[href^=\"/detail\"]::attr(href)').getall()\n",
    "print('prefix matched hrefs:', links_prefix)"
   ],
   "id": "4faf87e5f89ff261",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_text: ['苹果 ', '香蕉 ', '梨子 ']\n",
      "items_full 示例: <li class=\"item active\" data-id=\"101\">苹果 ...\n",
      "active id: 101\n",
      "['/detail/101', '/detail/102', '/detail/103']\n",
      "first li text: 苹果 \n",
      "prefix matched hrefs: ['/detail/101', '/detail/102', '/detail/103']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. requests + parsel 抓取在线页面 (可选)\n",
    "运行需要网络，示例使用 `quotes.toscrape.com`。若离线环境，可跳过。"
   ],
   "id": "6aa2387a9ba25fa7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "try:\n",
    "    r = requests.get('https://quotes.toscrape.com/', timeout=10)\n",
    "    r.raise_for_status()\n",
    "    page = Selector(text=r.text)\n",
    "    quotes = page.css('div.quote')\n",
    "    for q in quotes[:3]:\n",
    "        text = q.css('span.text::text').get()\n",
    "        author = q.css('small.author::text').get()\n",
    "        tags = q.css('div.tags a.tag::text').getall()\n",
    "        print(author, ':', text[:30], '...', tags)\n",
    "except Exception as e:\n",
    "    print('网络访问失败，跳过示例 ->', e)"
   ],
   "id": "6439ddf1034e6689"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BeautifulSoup (select)\n",
    "`BeautifulSoup` 支持 `.select()` 返回元素列表，以及 `.select_one()`。获取属性用 `el['attr']`，文本用 `.get_text(strip=True)`。伪类支持有限。"
   ],
   "id": "957e003c251536c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:19.865068Z",
     "start_time": "2025-11-13T11:30:19.781451Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(sample_html, 'lxml')\n",
    "li_nodes = soup.select('ul.items > li.item')\n",
    "print('总数:', len(li_nodes))\n",
    "print('第一个文本:', li_nodes[0].get_text(strip=True))\n",
    "active = soup.select_one('li.item.active')\n",
    "print('active data-id:', active['data-id'])\n",
    "hrefs = [a['href'] for a in soup.select('a.detail')]\n",
    "print('hrefs:', hrefs)"
   ],
   "id": "2ea34e4afbb12d18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数: 3\n",
      "第一个文本: 苹果详情\n",
      "active data-id: 101\n",
      "hrefs: ['/detail/101', '/detail/102', '/detail/103']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PyQuery\n",
    "`pyquery` 语法类似 jQuery：链式、`items()`、`text()`、`attr()`。非常适合熟悉前端的开发者。"
   ],
   "id": "2c320d7063342947"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:19.891197Z",
     "start_time": "2025-11-13T11:30:19.877324Z"
    }
   },
   "source": [
    "from pyquery import PyQuery as pq\n",
    "doc = pq(sample_html)\n",
    "for i, li in enumerate(doc('ul.items > li').items(), 1):\n",
    "    print(i, li.text(), 'data-id=', li.attr('data-id'))\n",
    "# 直接取所有链接 href\n",
    "print(doc('a.detail').attr('href'))  # 第一个\n",
    "print([a.attr('href') for a in doc('a.detail').items()])"
   ],
   "id": "3ba729b551f6d0f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 苹果 详情 data-id= 101\n",
      "2 香蕉 详情 data-id= 102\n",
      "3 梨子 详情 data-id= 103\n",
      "/detail/101\n",
      "['/detail/101', '/detail/102', '/detail/103']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. lxml 原生 + cssselect\n",
    "`lxml` 可用 `from lxml import html`，解析后调用 `.cssselect(selector)`。需确保已安装 `cssselect` 包 (通常随 lxml 一起被支持)。"
   ],
   "id": "419f80a0508631cb"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:19.921642Z",
     "start_time": "2025-11-13T11:30:19.913499Z"
    }
   },
   "source": [
    "from lxml import html\n",
    "tree = html.fromstring(sample_html)\n",
    "li_nodes = tree.cssselect('ul.items > li.item')\n",
    "print('数量:', len(li_nodes))\n",
    "print('第一个去除多余空白文本:', ''.join(li_nodes[0].text_content().split()))\n",
    "# 属性过滤 + 前缀匹配\n",
    "href_nodes = tree.cssselect('a.detail')\n",
    "print([n.get('href') for n in href_nodes])"
   ],
   "id": "ad716d19455bed2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数量: 3\n",
      "第一个去除多余空白文本: 苹果详情\n",
      "['/detail/101', '/detail/102', '/detail/103']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. selectolax (性能更好)\n",
    "`selectolax` 使用基于 Modest engine 的解析，速度快、占用低。CSS 支持子集 (不含复杂伪类)。适合大批量页面。"
   ],
   "id": "3b7726e7e46020ed"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:30:19.971109Z",
     "start_time": "2025-11-13T11:30:19.958240Z"
    }
   },
   "source": [
    "from selectolax.parser import HTMLParser\n",
    "parser = HTMLParser(sample_html)\n",
    "for li in parser.css('ul.items > li.item'):\n",
    "    # text() 返回拼接文本；attributes 字典\n",
    "    print(li.attributes.get('data-id'), li.text(strip=True))\n",
    "links = [a.attributes.get('href') for a in parser.css('a.detail')]\n",
    "print('links:', links)"
   ],
   "id": "db34a4365fc31b21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 苹果详情\n",
      "102 香蕉详情\n",
      "103 梨子详情\n",
      "links: ['/detail/101', '/detail/102', '/detail/103']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 常见技巧与坑\n",
    "1. 多类匹配：`.item.active` 是同时具有两个类；包含任一类要分两次或用 XPath。\n",
    "2. 空格 vs `>`：`div a` 后代任意深度；`div > a` 仅直接子代。\n",
    "3. 文本获取差异：`parsel` 用 `::text` 仅取直接文本节点；`BeautifulSoup` 的 `.get_text()` 合并所有后代。需要精准分离时用 `parsel` 或 `lxml`。\n",
    "4. 属性选择性能：前缀/后缀匹配 (`^=`, `$=`, `*=`) 在大 DOM 上较慢，可先粗选再过滤。\n",
    "5. 不支持的伪类：很多库不支持诸如 `:nth-of-type(odd)` 等高级选择器；必要时回退 XPath。\n",
    "6. 清理文本：多余空白/换行可用 `.strip()`、`re.sub(r'\\s+', ' ', text)`。\n",
    "7. 网络请求：频繁解析建议复用 Session，减少 TLS 握手开销。\n",
    "8. 编码：确保 `response.encoding` 正确，否则解析文本可能乱码。\n",
    "9. 性能基线：批量爬取时优先 `selectolax` 或 `lxml`，`BeautifulSoup` 更易用但慢。"
   ],
   "id": "a322489ed6de38c2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 小型速查表\n",
    "| 目标 | CSS 示例 | 说明 |\n",
    "|-------|-----------|------|\n",
    "| 所有 li | `li` | 标签名 |\n",
    "| class=detail 的 a | `a.detail` | 类匹配 |\n",
    "| id=main 的 div | `#main` | id |\n",
    "| ul.items 下直接子 li | `ul.items > li` | 子代 |\n",
    "| 任意后代 a | `#main a` | 后代 |\n",
    "| 有 href 属性的 a | `a[href]` | 属性存在 |\n",
    "| href 以 /detail 开头 | `a[href^=/detail]` | 前缀 |\n",
    "| href 以 .png 结尾 | `img[src$=.png]` | 后缀 |\n",
    "| data-id 含 10 | `li[data-id*=10]` | 子串 |\n",
    "| 第一个 li | `li:first-child` | 伪类 |\n",
    "| 第2个 li | `li:nth-child(2)` | 序号 |\n",
    "\n",
    "> 更多：MDN CSS Selectors 文档可作为权威参考。"
   ],
   "id": "1587df780a7b9dff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 总结\n",
    "- CSS 选择器语义直观，适合快速定位元素。\n",
    "- 各库差异主要体现在：API 风格、性能、伪类支持范围。\n",
    "- 与 XPath 结合使用可覆盖复杂场景。\n",
    "- 批量采集关注性能与内存，优先选择高性能解析器。\n",
    "\n",
    "可根据项目需求选取：`parsel` (Scrapy 生态)、`selectolax` (性能)、`BeautifulSoup` (易用)、`pyquery` (前端风格)、`lxml` (底层灵活)。"
   ],
   "id": "c409aa9727fec1ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
